{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98fbe77b-324d-4378-b943-ff93cb220b7f",
   "metadata": {},
   "source": [
    "# 通过开源模型直接在本地转录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1528b999-0fd4-43d5-985d-0f547d775030",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T16:17:19.347493Z",
     "iopub.status.busy": "2024-05-22T16:17:19.346939Z",
     "iopub.status.idle": "2024-05-22T16:17:23.947346Z",
     "shell.execute_reply": "2024-05-22T16:17:23.946527Z",
     "shell.execute_reply.started": "2024-05-22T16:17:19.347460Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease               \u001b[0m\n",
      "Hit:2 https://deb.nodesource.com/node_18.x nodistro InRelease                  \u001b[0m\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease                    \u001b[0m\u001b[33m\u001b[33m\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
      "Hit:4 https://developer.download.nvidia.cn/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
      "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease               \u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "Fetched 119 kB in 2s (57.2 kB/s)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "31 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 31 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt update &&  apt install -y ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "130e1f42-ca78-4ed5-8951-b3a2d570841c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T16:17:23.949600Z",
     "iopub.status.busy": "2024-05-22T16:17:23.948811Z",
     "iopub.status.idle": "2024-05-22T16:17:29.789848Z",
     "shell.execute_reply": "2024-05-22T16:17:29.788873Z",
     "shell.execute_reply.started": "2024-05-22T16:17:23.949566Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20231117)\n",
      "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.3.0)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.59.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.24.4)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.3.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.4)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.2.0)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper) (3.14.0)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.42.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper) (12.4.127)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: setuptools-rust in /usr/local/lib/python3.10/dist-packages (1.9.0)\n",
      "Requirement already satisfied: setuptools>=62.4 in /usr/local/lib/python3.10/dist-packages (from setuptools-rust) (70.0.0)\n",
      "Requirement already satisfied: semantic-version<3,>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from setuptools-rust) (2.10.0)\n",
      "Requirement already satisfied: tomli>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from setuptools-rust) (2.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai-whisper\n",
    "%pip install setuptools-rust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2deeef68-a0a1-470a-b3f6-ae952406cd80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T16:17:29.792096Z",
     "iopub.status.busy": "2024-05-22T16:17:29.791132Z",
     "iopub.status.idle": "2024-05-22T16:17:29.905575Z",
     "shell.execute_reply": "2024-05-22T16:17:29.903731Z",
     "shell.execute_reply.started": "2024-05-22T16:17:29.792052Z"
    }
   },
   "outputs": [],
   "source": [
    "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8468a013-6d66-44b7-ab14-a6924729dc76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T16:17:29.907396Z",
     "iopub.status.busy": "2024-05-22T16:17:29.907061Z",
     "iopub.status.idle": "2024-05-22T16:32:18.817472Z",
     "shell.execute_reply": "2024-05-22T16:32:18.815187Z",
     "shell.execute_reply.started": "2024-05-22T16:17:29.907370Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:65: UserWarning: /root/.cache/whisper/large-v3.pt exists, but the SHA256 checksum does not match; re-downloading the file\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████| 2.88G/2.88G [13:18<00:00, 3.87MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripted:  ./data/podcast_clip.mp3\n",
      "欢迎来到Onboard,真实的一线经验,走新的投资思考。我是Monica。我是高宁,我们一起聊聊软件如何改变世界。大家好,欢迎来到Onboard,我是Monica。自从OpenAI发布的ChatGPT掀起了席卷世界的AI热潮,不到三个月就积累了超过一亿的月活用户,超过1300万的日活用户。真的是展现了AI让人惊叹的能力,也让很多人直呼这就是下一个互联网的未来。有不少观众都说,希望我们再做一期AI的讨论,于是这次硬核讨论就来了。这次我们请来了Google Brain的研究员雪芝,她是Google大语言模型PALM,Pathways Language Model的作者之一。要知道,这个模型的参数量是GPT-3的三倍还多。另外还有两位AI产品大牛,一位来自著名的StableModels,StableDiffusion背后的商业公司StabilityAI,另一位来自某硅谷科技大厂,也曾在吴恩达教授的LandingAI中担任产品负责人。此外,莫妮凯还邀请到一位一直关注AI的投资人朋友Bill,当作我的特邀共同主持嘉宾。我们主要讨论几个话题,一方面,从研究的视角,最前沿的研究者在关注什么?现在的技术的天花板和未来大的变量可能会在哪里?从产品和商业的角度,什么是一个好的AI产品?整个状态可能随着技术有怎样的演变?更重要的,我们又能从上一波AI的创业热潮中学到什么?最后,莫妮凯和Bill还会从投资人的视角做一个回顾、总结和畅想。这里还有一个小的update,在本集发布的时候,Google也对爆发式增长的ChatGPT做出了回应,正在测试一个基于Lambda模型的聊天机器人ApprenticeBot,正式发布,我们都会有什么惊喜,我们都拭目以待。AI无理是未来几年最令人兴奋的变量之一,莫妮凯也希望未来能邀请到更多一线从业者从不同角度讨论这个话题,不论是想要做创业、研究、产品还是投资的同学,希望这些对话对于大家了解这些技术演进、商业的可能,甚至未来对于我们每个人、每个社会意味着什么,都能引发一些思考,提供一些启发。这些对话,这次的讨论有些技术硬核,需要各位对生存式AI大模型都有一些基础了解,讨论中涉及到的论文和重要概念,也会总结在本集的简介中,供大家复习参考。几位嘉宾在北美工作生活多年,夹杂英文在所难免,也请大家体谅了。欢迎来到未来,大家enjoy!可以大家先做一个简单的这个自我介绍,你们自己过去的一些经验,一个fun fact,就是你最喜欢的,\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"large\")\n",
    "def transcript(clip, prompt, output):\n",
    "    result = model.transcribe(clip, initial_prompt=prompt)\n",
    "    with open(output, \"w\") as f:\n",
    "        f.write(result['text'])\n",
    "    print(\"Transcripted: \", clip)\n",
    "    \n",
    "prompt = \"这是一段Onboard播客，里面会聊到ChatGPT以及PALM这个大语言模型。这个模型也叫做Pathways Language Model。\\n\\n\"\n",
    "\n",
    "clip = f\"./data/podcast_clip.mp3\"\n",
    "output = f\"./data/transcripts/podcast_clip.txt\"\n",
    "transcript(clip, prompt, output)\n",
    "with open(output, \"r\") as f:\n",
    "    transcript = f.read()\n",
    "    print(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412bd034-b776-4e1e-9330-7d37e732a95e",
   "metadata": {},
   "source": [
    "# 结合ChatGPT做内容小结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f207ee02-9f75-49cf-be84-53aa31ec9a6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T16:32:18.825892Z",
     "iopub.status.busy": "2024-05-22T16:32:18.824819Z",
     "iopub.status.idle": "2024-05-22T16:32:28.508993Z",
     "shell.execute_reply": "2024-05-22T16:32:28.508153Z",
     "shell.execute_reply.started": "2024-05-22T16:32:18.825847Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_93/770114377.py:12: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context  = ServiceContext.from_defaults(llm=llm)\n",
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.predict_messages` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "播客内容主要围绕AI技术的发展和应用展开讨论，涉及到了ChatGPT等大型AI模型的影响和潜力，以及从研究、产品、商业和投资等多个角度对AI的探讨。嘉宾们分享了他们的经验和见解，展望了AI技术的未来发展，并提供了对AI技术演进和商业应用的启发和思考。\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.text_splitter import SpacyTextSplitter\n",
    "from llama_index.core import GPTListIndex, ServiceContext, SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "\n",
    "llm = ChatOpenAI(temperature=0,model_name=\"gpt-3.5-turbo\", max_tokens=1024)\n",
    "text_splitter = SpacyTextSplitter(pipeline=\"zh_core_web_sm\", chunk_size = 2048)\n",
    "parser = SimpleNodeParser(chunking_tokenizer_fn=text_splitter.split_text)\n",
    "documents = SimpleDirectoryReader('./data/transcripts').load_data()\n",
    "nodes = parser.get_nodes_from_documents(documents)\n",
    "\n",
    "service_context  = ServiceContext.from_defaults(llm=llm)\n",
    "index = GPTListIndex(nodes=nodes, service_context=service_context)\n",
    "query_engine = index.as_query_engine(response_mode=\"tree_summarize\")\n",
    "\n",
    "response = query_engine.query(\"请你用中文总结一下我们的播客内容:\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
