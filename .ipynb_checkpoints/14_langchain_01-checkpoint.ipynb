{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2084f07-db09-45c5-87c3-3e1a0b3e6a3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T15:11:09.954858Z",
     "iopub.status.busy": "2024-04-23T15:11:09.954533Z",
     "iopub.status.idle": "2024-04-23T15:11:15.704055Z",
     "shell.execute_reply": "2024-04-23T15:11:15.703230Z",
     "shell.execute_reply.started": "2024-04-23T15:11:09.954827Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.21.2)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.16)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.1.3-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.33)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.44)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.48)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2024.4.16)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Downloading langchain_openai-0.1.3-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: langchain-openai\n",
      "Successfully installed langchain-openai-0.1.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1b02aa-2174-4cb1-a48d-6a3b3068defb",
   "metadata": {},
   "source": [
    "# 多次调用完成中译英，英文文答，英译中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6706f899-c5c9-42f6-b327-512d82b9d1c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T15:57:26.043180Z",
     "iopub.status.busy": "2024-04-23T15:57:26.042170Z",
     "iopub.status.idle": "2024-04-23T15:57:50.789004Z",
     "shell.execute_reply": "2024-04-23T15:57:50.788020Z",
     "shell.execute_reply.started": "2024-04-23T15:57:26.043141Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an expert in machine learning, could you please explain the principles of CNN?\n",
      "Certainly! Convolutional Neural Networks (CNNs) are a type of deep learning model commonly used for image recognition and computer vision tasks. The key principles of CNNs include:\n",
      "\n",
      "1. Convolutional Layers: The core building block of a CNN is the convolutional layer. This layer applies a set of filters (also known as kernels) to the input image to extract features. Each filter slides over the input image, performing element-wise multiplication and summing up the results to produce a feature map.\n",
      "\n",
      "2. Pooling Layers: Pooling layers are used to reduce the spatial dimensions of the feature maps produced by the convolutional layers. Common pooling operations include max pooling and average pooling, which downsample the feature maps by taking the maximum or average value within a certain window.\n",
      "\n",
      "3. Activation Functions: Non-linear activation functions like ReLU (Rectified Linear Unit) are typically applied after each convolutional and pooling layer to introduce non-linearity into the network and enable it to learn complex patterns in the data.\n",
      "\n",
      "4. Fully Connected Layers: After several convolutional and pooling layers, the final feature maps are flattened and passed through one or more fully connected layers to make predictions. These layers perform classification or regression tasks based on the learned features.\n",
      "\n",
      "5. Backpropagation: CNNs are trained using the backpropagation algorithm, which adjusts the weights of the network to minimize the difference between the predicted output and the ground truth labels. This process involves calculating gradients of the loss function with respect to the network parameters and updating the weights using optimization techniques like stochastic gradient descent.\n",
      "\n",
      "Overall, CNNs leverage the principles of convolution, pooling, non-linear activation, and backpropagation to automatically learn hierarchical representations of data and make accurate predictions in tasks like image classification, object detection, and segmentation.\n",
      "当然！卷积神经网络（CNNs）是一种常用于图像识别和计算机视觉任务的深度学习模型。CNNs的关键原则包括：\n",
      "\n",
      "1. 卷积层：CNN的核心构建模块是卷积层。这一层将一组滤波器（也称为卷积核）应用于输入图像以提取特征。每个滤波器在输入图像上滑动，执行逐元素乘法并将结果求和以生成特征图。\n",
      "\n",
      "2. 池化层：池化层用于减小由卷积层产生的特征图的空间维度。常见的池化操作包括最大池化和平均池化，通过在特定窗口内取最大值或平均值来降低特征图的分辨率。\n",
      "\n",
      "3. 激活函数：非线性激活函数如ReLU（修正线性单元）通常应用于每个卷积和池化层之后，引入非线性到网络中，使其能够学习数据中的复杂模式。\n",
      "\n",
      "4. 全连接层：在经过多个卷积和池化层之后，最终的特征图被展平并通过一个或多个全连接层进行预测。这些层基于学习到的特征执行分类或回归任务。\n",
      "\n",
      "5. 反向传播：CNNs使用反向传播算法进行训练，调整网络的权重以最小化预测输出与真实标签之间的差异。这个过程包括计算损失函数相对于网络参数的梯度，并使用随机梯度下降等优化技术更新权重。\n",
      "\n",
      "总的来说，CNNs利用卷积、池化、非线性激活和反向传播的原则来自动学习数据的层次表示，并在图像分类、目标检测和分割等任务中进行准确预测。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", max_tokens=2048, temperature=0.5)\n",
    "\n",
    "en_to_zh_prompt = PromptTemplate(\n",
    "     template=\"请把下面这句话翻译成英文： \\n\\n {question}?\", input_variables=[\"question\"]\n",
    ")\n",
    "\n",
    "question_prompt = PromptTemplate(\n",
    "    template = \"{english_question}\", input_variables=[\"english_question\"]\n",
    ")\n",
    "\n",
    "zh_to_cn_prompt = PromptTemplate(\n",
    "    input_variables=[\"english_answer\"],\n",
    "    template=\"请把下面这一段翻译成中文： \\n\\n{english_answer}?\",\n",
    ")\n",
    "\n",
    "question_translate_chain = LLMChain(llm=llm, prompt=en_to_zh_prompt, output_key=\"english_question\")\n",
    "english = question_translate_chain.run(question=\"请你作为一个机器学习的专家，介绍一下CNN的原理。\")\n",
    "print(english)\n",
    "\n",
    "qa_chain = LLMChain(llm=llm, prompt=question_prompt, output_key=\"english_answer\")\n",
    "english_answer = qa_chain.run(english_question=english)\n",
    "print(english_answer)\n",
    "\n",
    "answer_translate_chain = LLMChain(llm=llm, prompt=zh_to_cn_prompt)\n",
    "answer = answer_translate_chain.run(english_answer=english_answer)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dac077-4901-41ac-9e88-fabebf30a283",
   "metadata": {},
   "source": [
    "# 使用Langchain简化实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a55c5c52-a5dd-43f3-a824-55bb8b984734",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:20:08.479239Z",
     "iopub.status.busy": "2024-04-23T16:20:08.478564Z",
     "iopub.status.idle": "2024-04-23T16:20:34.307858Z",
     "shell.execute_reply": "2024-04-23T16:20:34.306995Z",
     "shell.execute_reply.started": "2024-04-23T16:20:08.479202Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mAs an expert in machine learning, could you please introduce the principles of CNN (Convolutional Neural Network)?\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mCertainly! Convolutional Neural Networks (CNNs) are a type of deep neural network that are primarily used for image recognition and classification tasks. The key principles of CNNs include:\n",
      "\n",
      "1. Convolutional Layers: CNNs use convolutional layers to extract features from input images. These layers apply a series of filters (also known as kernels) to the input image, which helps to capture patterns and features present in the image.\n",
      "\n",
      "2. Pooling Layers: Pooling layers are used to reduce the spatial dimensions of the feature maps produced by the convolutional layers. This helps to make the network more computationally efficient and reduces the risk of overfitting.\n",
      "\n",
      "3. Activation Functions: Activation functions are used to introduce non-linearity into the network, allowing it to learn complex patterns and relationships in the data. Common activation functions used in CNNs include ReLU (Rectified Linear Unit) and Sigmoid.\n",
      "\n",
      "4. Fully Connected Layers: After the convolutional and pooling layers, CNNs typically have one or more fully connected layers that perform the final classification task. These layers take the features extracted by the earlier layers and use them to make predictions about the input image.\n",
      "\n",
      "5. Backpropagation: CNNs are trained using backpropagation, a technique that adjusts the weights of the network based on the error between the predicted output and the ground truth labels. This process is repeated iteratively until the network converges to a set of weights that minimize the error.\n",
      "\n",
      "Overall, CNNs are highly effective for tasks such as image classification, object detection, and image segmentation, and have been widely used in a variety of applications, including computer vision, natural language processing, and autonomous driving.\u001b[0m\n",
      "\u001b[38;5;200m\u001b[1;3m当然！卷积神经网络（CNNs）是一种深度神经网络，主要用于图像识别和分类任务。CNNs的关键原则包括：\n",
      "\n",
      "1. 卷积层：CNNs使用卷积层从输入图像中提取特征。这些层将一系列滤波器（也称为卷积核）应用于输入图像，有助于捕捉图像中存在的模式和特征。\n",
      "\n",
      "2. 池化层：池化层用于减少卷积层产生的特征图的空间维度。这有助于使网络更具计算效率，并减少过拟合的风险。\n",
      "\n",
      "3. 激活函数：激活函数用于在网络中引入非线性，使其能够学习数据中复杂的模式和关系。在CNNs中常用的激活函数包括ReLU（修正线性单元）和Sigmoid。\n",
      "\n",
      "4. 全连接层：在卷积和池化层之后，CNNs通常具有一个或多个全连接层，用于执行最终的分类任务。这些层获取之前层提取的特征，并用它们对输入图像进行预测。\n",
      "\n",
      "5. 反向传播：CNNs使用反向传播进行训练，这是一种根据预测输出与实际标签之间的误差调整网络权重的技术。这个过程被迭代重复，直到网络收敛到最小化误差的权重集。\n",
      "\n",
      "总的来说，CNNs在图像分类、目标检测和图像分割等任务中非常有效，并已广泛应用于各种应用领域，包括计算机视觉、自然语言处理和自动驾驶。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "当然！卷积神经网络（CNNs）是一种深度神经网络，主要用于图像识别和分类任务。CNNs的关键原则包括：\n",
      "\n",
      "1. 卷积层：CNNs使用卷积层从输入图像中提取特征。这些层将一系列滤波器（也称为卷积核）应用于输入图像，有助于捕捉图像中存在的模式和特征。\n",
      "\n",
      "2. 池化层：池化层用于减少卷积层产生的特征图的空间维度。这有助于使网络更具计算效率，并减少过拟合的风险。\n",
      "\n",
      "3. 激活函数：激活函数用于在网络中引入非线性，使其能够学习数据中复杂的模式和关系。在CNNs中常用的激活函数包括ReLU（修正线性单元）和Sigmoid。\n",
      "\n",
      "4. 全连接层：在卷积和池化层之后，CNNs通常具有一个或多个全连接层，用于执行最终的分类任务。这些层获取之前层提取的特征，并用它们对输入图像进行预测。\n",
      "\n",
      "5. 反向传播：CNNs使用反向传播进行训练，这是一种根据预测输出与实际标签之间的误差调整网络权重的技术。这个过程被迭代重复，直到网络收敛到最小化误差的权重集。\n",
      "\n",
      "总的来说，CNNs在图像分类、目标检测和图像分割等任务中非常有效，并已广泛应用于各种应用领域，包括计算机视觉、自然语言处理和自动驾驶。\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chinese_qa_chain = SimpleSequentialChain(\n",
    "    chains=[question_translate_chain, qa_chain, answer_translate_chain],\n",
    "    input_key=\"question\",\n",
    "    verbose=True,\n",
    ")\n",
    "answer = chinese_qa_chain.run(question=\"请你作为一个机器学习的专家，介绍一下CNN的原理。\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5961be1-9476-4216-86ef-14bb143fd264",
   "metadata": {},
   "source": [
    "# 多步骤引入不同输入参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acc27559-3cd7-4d12-8b40-cc16e224ad3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:23:35.680964Z",
     "iopub.status.busy": "2024-04-23T16:23:35.679181Z",
     "iopub.status.idle": "2024-04-23T16:23:44.128824Z",
     "shell.execute_reply": "2024-04-23T16:23:44.128133Z",
     "shell.execute_reply.started": "2024-04-23T16:23:35.680887Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "皇家马德里队获得欧冠的次数更多，他们共获得了13次欧冠冠军，而国际米兰则获得了3次欧冠冠军。\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "q1_prompt = PromptTemplate(\n",
    "    input_variables=[\"year1\"],\n",
    "    template=\"{year1}年的欧冠联赛的冠军是哪支球队，只说球队名称。\"\n",
    ")\n",
    "q2_prompt = PromptTemplate(\n",
    "    input_variables=[\"year2\"],\n",
    "    template=\"{year2}年的欧冠联赛的冠军是哪支球队，只说球队名称。\"\n",
    ")\n",
    "q3_prompt = PromptTemplate(\n",
    "    input_variables=[\"team1\", \"team2\"],\n",
    "    template=\"{team1}和{team2}哪只球队获得欧冠的次数多一些？\"\n",
    ")\n",
    "chain1 = LLMChain(llm=llm, prompt=q1_prompt, output_key=\"team1\")\n",
    "chain2 = LLMChain(llm=llm, prompt=q2_prompt, output_key=\"team2\")\n",
    "chain3 = LLMChain(llm=llm, prompt=q3_prompt)\n",
    "\n",
    "sequential_chain = SequentialChain(chains=[chain1, chain2, chain3], input_variables=[\"year1\", \"year2\"], verbose=True)\n",
    "answer = sequential_chain.run(year1=2000, year2=2010)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7f6188-5064-41dd-af7e-3cb250e497fe",
   "metadata": {},
   "source": [
    "# 通过Langchain来完成自动撰写单元测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "990ca440-59cb-49ec-8c6a-f30333490294",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:31:47.669206Z",
     "iopub.status.busy": "2024-04-23T16:31:47.668855Z",
     "iopub.status.idle": "2024-04-23T16:32:01.169315Z",
     "shell.execute_reply": "2024-04-23T16:32:01.168439Z",
     "shell.execute_reply.started": "2024-04-23T16:31:47.669179Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! stop is not default parameter.\n",
      "                stop was transferred to model_kwargs.\n",
      "                Please confirm that stop is what you intended.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! stop is not default parameter.\n",
      "                stop was transferred to model_kwargs.\n",
      "                Please confirm that stop is what you intended.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! stop is not default parameter.\n",
      "                stop was transferred to model_kwargs.\n",
      "                Please confirm that stop is what you intended.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "def format_time(seconds):\n",
      "    minutes, seconds = divmod(seconds, 60)\n",
      "    hours, minutes = divmod(minutes, 60)\n",
      "    if hours > 0:\n",
      "        return f\"{hours}h{minutes}min{seconds}s\"\n",
      "    elif minutes > 0:\n",
      "        return f\"{minutes}min{seconds}s\"\n",
      "    else:\n",
      "        return f\"{seconds}s\"\n",
      "#Below, each test case is represented by a tuple passed to the @pytest.mark.parametrize decorator\n",
      "#The first element of the tuple is the input to the function and the second element is the expected output\n",
      "@pytest.mark.parametrize(\n",
      "    \"input, expected_output\",\n",
      "    [\n",
      "        (3600, \"1h0min0s\"),\n",
      "        (3665, \"1h1min5s\"),\n",
      "        (7200, \"2h0min0s\"),\n",
      "        (120, \"2min0s\"),\n",
      "        (125, \"2min5s\"),\n",
      "        (360, \"6min0s\"),\n",
      "        (10, \"10s\"),\n",
      "        (30, \"30s\"),\n",
      "        (59, \"59s\"),\n",
      "        (-1, None),  # we expect an error for negative inputs\n",
      "        (\"abc\", None),  # we expect an error for non-numeric inputs\n",
      "        (None, None),  # we expect an error for None inputs\n",
      "    ],\n",
      ")\n",
      "def test_format_time(input, expected_output):\n",
      "    # use the pytest assertion to check if the output of the function matches the expected output\n",
      "    assert format_time(input) == expected_output\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "def write_unit_test(function_to_test, unit_test_package = \"pytest\"):\n",
    "    # 解释源代码的步骤\n",
    "    explain_code = \"\"\"\"# How to write great unit tests with {unit_test_package}\n",
    "\n",
    "    In this advanced tutorial for experts, we'll use Python 3.10 and `{unit_test_package}` to write a suite of unit tests to verify the behavior of the following function.\n",
    "    ```python\n",
    "    {function_to_test}\n",
    "    ```\n",
    "\n",
    "    Before writing any unit tests, let's review what each element of the function is doing exactly and what the author's intentions may have been.\n",
    "    - First,\"\"\"\n",
    "\n",
    "    explain_code_template = PromptTemplate(\n",
    "        input_variables=[\"unit_test_package\", \"function_to_test\"],\n",
    "        template=explain_code\n",
    "    )\n",
    "    explain_code_llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0.4, max_tokens=1000,\n",
    "            top_p=1, stop=[\"\\n\\n\", \"\\n\\t\\n\", \"\\n    \\n\"])\n",
    "    explain_code_step = LLMChain(llm=explain_code_llm, prompt=explain_code_template, output_key=\"code_explaination\")\n",
    "\n",
    "    # 创建测试计划示例的步骤\n",
    "    test_plan = \"\"\"\n",
    "\n",
    "    A good unit test suite should aim to:\n",
    "    - Test the function's behavior for a wide range of possible inputs\n",
    "    - Test edge cases that the author may not have foreseen\n",
    "    - Take advantage of the features of `{unit_test_package}` to make the tests easy to write and maintain\n",
    "    - Be easy to read and understand, with clean code and descriptive names\n",
    "    - Be deterministic, so that the tests always pass or fail in the same way\n",
    "\n",
    "    `{unit_test_package}` has many convenient features that make it easy to write and maintain unit tests. We'll use them to write unit tests for the function above.\n",
    "\n",
    "    For this particular function, we'll want our unit tests to handle the following diverse scenarios (and under each scenario, we include a few examples as sub-bullets):\n",
    "    -\"\"\"\n",
    "    test_plan_template = PromptTemplate(\n",
    "        input_variables=[\"unit_test_package\", \"function_to_test\", \"code_explaination\"],\n",
    "        template= explain_code + \"{code_explaination}\" + test_plan\n",
    "    )\n",
    "    test_plan_llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", max_tokens=1000, temperature=0.5,\n",
    "            top_p=1, stop=[\"\\n\\n\", \"\\n\\t\\n\", \"\\n    \\n\"])\n",
    "    test_plan_step = LLMChain(llm=test_plan_llm, prompt=test_plan_template, output_key=\"test_plan\")\n",
    "\n",
    "    # 撰写测试代码的步骤\n",
    "    starter_comment = \"Below, each test case is represented by a tuple passed to the @pytest.mark.parametrize decorator\"\n",
    "    prompt_to_generate_the_unit_test = \"\"\"\n",
    "\n",
    "Before going into the individual tests, let's first look at the complete suite of unit tests as a cohesive whole. We've added helpful comments to explain what each line does.\n",
    "```python\n",
    "import {unit_test_package}  # used for our unit tests\n",
    "\n",
    "{function_to_test}\n",
    "\n",
    "#{starter_comment}\"\"\"\n",
    "\n",
    "    unit_test_template = PromptTemplate(\n",
    "        input_variables=[\"unit_test_package\", \"function_to_test\", \"code_explaination\", \"test_plan\", \"starter_comment\"],\n",
    "        template= explain_code + \"{code_explaination}\" + test_plan + \"{test_plan}\" + prompt_to_generate_the_unit_test\n",
    "    )\n",
    "    unit_test_llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0.4, max_tokens=1000, stop=\"```\")\n",
    "    unit_test_step = LLMChain(llm=unit_test_llm, prompt=unit_test_template, output_key=\"unit_test\")\n",
    "\n",
    "    sequential_chain = SequentialChain(chains=[explain_code_step, test_plan_step, unit_test_step],\n",
    "                                    input_variables=[\"unit_test_package\", \"function_to_test\", \"starter_comment\"], verbose=True)\n",
    "    answer = sequential_chain.run(unit_test_package=unit_test_package, function_to_test=function_to_test, starter_comment=starter_comment)\n",
    "    return f\"\"\"#{starter_comment}\"\"\" + answer\n",
    "\n",
    "code = \"\"\"\n",
    "def format_time(seconds):\n",
    "    minutes, seconds = divmod(seconds, 60)\n",
    "    hours, minutes = divmod(minutes, 60)\n",
    "    if hours > 0:\n",
    "        return f\"{hours}h{minutes}min{seconds}s\"\n",
    "    elif minutes > 0:\n",
    "        return f\"{minutes}min{seconds}s\"\n",
    "    else:\n",
    "        return f\"{seconds}s\"\n",
    "\"\"\"\n",
    "\n",
    "import ast\n",
    "\n",
    "def write_unit_test_automatically(code, retry=3):\n",
    "    unit_test_code = write_unit_test(code)\n",
    "    all_code = code + unit_test_code\n",
    "    tried = 0\n",
    "    while tried < retry:\n",
    "        try:\n",
    "            ast.parse(all_code)\n",
    "            return all_code\n",
    "        except SyntaxError as e:\n",
    "            print(f\"Syntax error in generated code: {e}\")\n",
    "            all_code = code + write_unit_test(code)\n",
    "            tried += 1\n",
    "\n",
    "print(write_unit_test_automatically(code))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
