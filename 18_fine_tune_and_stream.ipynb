{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "885d688d-e687-4be6-b3af-d1cd9af04d4e",
   "metadata": {},
   "source": [
    "# 构造故事数据，注意，以下代码较慢且耗费较多Token，可以不运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b371972-4590-4054-a1ee-bac9abd6b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,openai,backoff\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key = os.environ[\"OPENAI_API_KEY\"])\n",
    "dynasties= ['唐', '宋', '元', '明', '清', '汉', '魏', '晋', '南北朝']\n",
    "super_powers = ['隐形', '飞行', '读心术', '瞬间移动', '不死之身', '喷火']\n",
    "story_types = ['轻松', '努力', '艰难']\n",
    "\n",
    "@backoff.on_exception(backoff.expo, openai.RateLimitError)\n",
    "def gpt35(prompt, max_tokens=2048, temperature=0.5, top_p=1, frequency_penalty=0, presence_penalty=0):\n",
    "    response = client.completions.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty)\n",
    "    return response.choices[0].text\n",
    "\n",
    "def prepare_stories(dynasties, super_powers, story_types, repeat=3, output_file=\"data/ultraman_stories.csv\"):\n",
    "    df = pd.DataFrame()\n",
    "    for dynasty in dynasties:\n",
    "        for super_power in super_powers:\n",
    "            for story_type in story_types:\n",
    "                   for i in range(repeat):\n",
    "                        prompt = f\"\"\"请你用中文写一段300字的故事，情节跌宕起伏，讲述一位{dynasty}朝时期的英雄人物，穿越到现代，拥有了{super_power}这样的超能力，通过{story_type}的战斗，帮助奥特曼一起打败了怪兽的故事。\"\"\"\n",
    "                        story = gpt35(prompt)\n",
    "                        row = {\"dynasty\": dynasty, \"super_power\": super_power, \"story_type\": story_type, \"story\": story}\n",
    "                        row = pd.DataFrame([row])\n",
    "                        df = pd.concat([df, row], axis=0, ignore_index=True)\n",
    "\n",
    "    df.to_csv(\"data/ultraman_stories.csv\")\n",
    "\n",
    "prepare_stories(dynasties, super_powers, story_types)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b186c33-d4e1-41c7-8470-dc19c780ea72",
   "metadata": {},
   "source": [
    "# 读取CSV，构造微调数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d6c3da1-369f-41f1-87f2-825192c1baf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T14:17:22.564315Z",
     "iopub.status.busy": "2024-05-05T14:17:22.563538Z",
     "iopub.status.idle": "2024-05-05T14:17:23.463451Z",
     "shell.execute_reply": "2024-05-05T14:17:23.462647Z",
     "shell.execute_reply.started": "2024-05-05T14:17:22.564286Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Based on your file extension, your file is formatted as a CSV file\n",
      "- Your file contains 464 prompt-completion pairs\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples.\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Necessary] Your format `CSV` will be converted to `JSONL`\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: Y\n",
      "- [Recommended] Add a suffix ending `.` to all completions [Y/n]: Y\n",
      "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified file to `data/prepared_data_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"data/prepared_data_prepared.jsonl\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 8.82 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['openai', 'tools', 'fine_tunes.prepare_data', '--file', 'data/prepared_data.csv', '--quiet'], returncode=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/ultraman_stories.csv\")\n",
    "df['sub_prompt'] = df['dynasty'] + \",\" + df['super_power'] + \",\" + df['story_type']\n",
    "prepared_data = df.loc[:,['sub_prompt','story']]\n",
    "prepared_data.rename(columns={'sub_prompt':'prompt', 'story':'completion'}, inplace=True)\n",
    "prepared_data.to_csv('data/prepared_data.csv',index=False)\n",
    "\n",
    "import subprocess\n",
    "\n",
    "subprocess.run('openai tools fine_tunes.prepare_data --file data/prepared_data.csv --quiet'.split())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec6d5ae-8273-4899-a08e-d36d6138bc70",
   "metadata": {},
   "source": [
    "# 模型微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b1c8a9-2fec-40d5-8c59-acde068e83e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "file = client.files.create(\n",
    "  file=open(\"data/prepared_data_prepared.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "client.fine_tuning.jobs.create(\n",
    "  training_file=file.id, \n",
    "  model=\"babbage-002\",\n",
    "  suffix=\"ultraman\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fd71717-d967-454a-86c7-4c1da02b6556",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T14:20:22.437029Z",
     "iopub.status.busy": "2024-05-05T14:20:22.436445Z",
     "iopub.status.idle": "2024-05-05T14:20:24.110741Z",
     "shell.execute_reply": "2024-05-05T14:20:24.109898Z",
     "shell.execute_reply.started": "2024-05-05T14:20:22.436998Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJob](data=[], object='list', has_more=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a97b818-5721-4f15-a038-f1ba82b14a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "def write_a_story(prompt):\n",
    "    response = client.completions.create(\n",
    "        model=\"[微调出的模型名称]\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,\n",
    "        max_tokens=2000,\n",
    "        top_p=1,\n",
    "        stop=[\".\"])\n",
    "    return response.choices[0].text\n",
    "\n",
    "story = write_a_story(\"宋,发射激光,艰难 ->\\n\")\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25008975-4f0c-4863-a092-8ccc257a7149",
   "metadata": {},
   "outputs": [],
   "source": [
    "story = write_a_story(\"秦,龙卷风,辛苦 ->\\n\")\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dbf1e1-7b2b-4147-96b9-83c656f3eeec",
   "metadata": {},
   "source": [
    "# 增量训练优化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403c409e-7e24-4827-bcd1-b34b1a693e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成额外的数据代码\n",
    "dynasties= ['秦', '五代', '隋']\n",
    "super_powers = ['龙卷风', '冰冻大海', '流星火雨']\n",
    "story_types = ['轻松', '努力', '艰难', '勇敢', '辛苦']\n",
    "\n",
    "new_stories = \"data/ultraman_stories_more.csv\"\n",
    "prepare_stories(dynasties, super_powers, story_types, repeat=3, output_file=new_stories)\n",
    "\n",
    "\n",
    "#数据转换\n",
    "df = pd.read_csv(new_stories)\n",
    "df['sub_prompt'] = df['dynasty'] + \",\" + df['super_power'] + \",\" + df['story_type']\n",
    "prepared_data = df.loc[:,['sub_prompt','story']]\n",
    "prepared_data.rename(columns={'sub_prompt':'prompt', 'story':'completion'}, inplace=True)\n",
    "new_stories_prepared = 'data/prepared_data_more.csv'\n",
    "prepared_data.to_csv(new_stories_prepared, index=False)\n",
    "\n",
    "subprocess.run('openai tools fine_tunes.prepare_data --file data/prepared_data_more.csv --quiet'.split())\n",
    "\n",
    "\n",
    "#继续微调\n",
    "from openai.types.fine_tuning.job_create_params import Hyperparameters\n",
    "\n",
    "file = client.files.create(\n",
    "  file=open(\"data/prepared_data_more_prepared.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "client.fine_tuning.jobs.create(\n",
    "  training_file=file.id,\n",
    "  model=\"[上面微调过的模型名]\",\n",
    "  suffix=\"ultraman\",\n",
    "  hyperparameters=Hyperparameters(learning_rate_multiplier=0.2)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d3f709-1e68-4ffc-b81c-2ed4fc82797e",
   "metadata": {},
   "source": [
    "# 流式生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5faf3c3-e942-4eb5-a09b-760bb0e356f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_a_story_by_stream(prompt):\n",
    "    response = client.completions.create(\n",
    "        model=\"[上面微调过的模型名]\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,\n",
    "        max_tokens=2000,\n",
    "        stream=True,\n",
    "        top_p=1,\n",
    "        stop=[\".\"])\n",
    "    return response\n",
    "\n",
    "response = write_a_story_by_stream(\"汉,冰冻大海,艰难 ->\\n\")\n",
    "\n",
    "for event in response:\n",
    "    event_text = event.choices[0].text\n",
    "    print(event_text, end = '')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
